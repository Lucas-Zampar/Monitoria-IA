{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b79c85dc",
   "metadata": {},
   "source": [
    "# Instalação"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2bc4422",
   "metadata": {},
   "source": [
    "A fim de desenvolver modelos de deep learning para grafos, será necessário instalar o módulo Pytorch Geometric. Para tanto, iremos desinstalar a versão atual do Pytorch pelo seguinte código:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "83d04c60",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n!pip3 uninstall torchtext -y\\n!pip3 uninstall torchvision -y\\n!pip3 uninstall torch -y\\n'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "!pip3 uninstall torchtext -y\n",
    "!pip3 uninstall torchvision -y\n",
    "!pip3 uninstall torch -y\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85db7d86",
   "metadata": {},
   "source": [
    "A partir disso, iremos instalar a versão 1.9.0, anterior a atual:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a5df8512",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip3 install torch==1.9.0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e30d3997",
   "metadata": {},
   "source": [
    "Com isso, poderemos baixar o pacote do Pytorch Geometric. Caso não seja instalado, reinicie a máquina, pois a instalação da nova versão do Pytorch pode não ter sido salva corretamente na máquina virtual."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "205b999c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\nimport torch\\n\\nif torch.__version__ != '1.9.0+cu102':\\n    print('Versão do pytorch inadequada! Favor reiniciar a máquina virtual.')\\nelse:    \\n    pytorch_version=f'torch-{torch.__version__}.html'\\n    !pip3 install --no-index torch-scatter -f https://pytorch-geometric.com/whl/$pytorch_version\\n    !pip3 install --no-index torch-sparse -f https://pytorch-geometric.com/whl/$pytorch_version\\n    !pip3 install --no-index torch-cluster -f https://pytorch-geometric.com/whl/$pytorch_version\\n    !pip3 install --no-index torch-spline-conv -f https://pytorch-geometric.com/whl/$pytorch_version\\n    !pip3 install torch-geometric\\n\""
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "import torch\n",
    "\n",
    "if torch.__version__ != '1.9.0+cu102':\n",
    "    print('Versão do pytorch inadequada! Favor reiniciar a máquina virtual.')\n",
    "else:    \n",
    "    pytorch_version=f'torch-{torch.__version__}.html'\n",
    "    !pip3 install --no-index torch-scatter -f https://pytorch-geometric.com/whl/$pytorch_version\n",
    "    !pip3 install --no-index torch-sparse -f https://pytorch-geometric.com/whl/$pytorch_version\n",
    "    !pip3 install --no-index torch-cluster -f https://pytorch-geometric.com/whl/$pytorch_version\n",
    "    !pip3 install --no-index torch-spline-conv -f https://pytorch-geometric.com/whl/$pytorch_version\n",
    "    !pip3 install torch-geometric\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ecd118b",
   "metadata": {},
   "source": [
    "# 1- Representação de um grafo"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c25adddc",
   "metadata": {},
   "source": [
    "Como introdução ao PyG, vamos construir o grafo definido pela equação abaixo:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca9907a6",
   "metadata": {},
   "source": [
    "$$ G = \\{ V, E \\} $$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8251115a",
   "metadata": {},
   "source": [
    "Em que:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8442df7",
   "metadata": {},
   "source": [
    "$$ V = \\{ \\{0, 1, 2 \\} \\} $$\n",
    "$$ E = \\{ \\{0, 1\\}, \\{1, 2\\} \\} $$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "829b5923",
   "metadata": {},
   "source": [
    "Note que o grafo G é composto por três vértices {0,1,2} e por duas arestas {{0,1},{1,2}}, sendo não dirigido."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17b8326a",
   "metadata": {},
   "source": [
    "No PyG, um grafo é representado como uma instância da classe <code>torch_geometric.data.Data</code>. Portanto, devemos importá-la de modo a construir o grafo. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21c2d6fe",
   "metadata": {},
   "source": [
    "Além disso, importaremos também o módulo <code>torch</code> com a finalidade de utilizar algumas funcionalidades do Pytorch, como os tensores."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7c2054ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch_geometric.data import Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34e55827",
   "metadata": {},
   "source": [
    "## 1.1- Representando as arestas"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "218477f0",
   "metadata": {},
   "source": [
    "A classe <code>Data</code> espera receber a representação das arestas no formato <code>COO</code> (COOrdinate). Nele, a conectividade do grafo é representada por meio de uma matriz com duas linhas, a primeira se referindo aos vértices de origem; a segunda, aos de destino. Dessa forma, os dois vértices em uma mesma coluna compõem a aresta em questão."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e09242e0",
   "metadata": {},
   "source": [
    "Usualmente,tal matriz é referida como <code>edge_index</code>, sendo implementada por um tensor do tipo <code>torch.long</code>:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8050dbe7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0, 1, 1, 2],\n",
       "        [1, 0, 2, 1]])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "edge_index = torch.tensor([[0, 1, 1, 2],\n",
    "                          [1, 0, 2, 1]], dtype=torch.long)\n",
    "edge_index"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89d75737",
   "metadata": {},
   "source": [
    "Perceba que, na primeria coluna, encontram-se os vértices 0 e 1 respectivamente, representando uma aresta que parte de 0 em direção a 1. Já na segunda coluna, novamente encontramos os vértices 0 e 1, porém na ordem inversa, indicando que agora a aresta parte de 1 em direção a 0. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52988fee",
   "metadata": {},
   "source": [
    "Tal notação, embora pareça redundante, é necessária para sinalizar que o grafo é não dirigido. O mesmo padrão se repete para as duas últimas colunas, as quais representam a aresta {1,2}."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4083cbf1",
   "metadata": {},
   "source": [
    "Outra forma de definir as arestas seria por meio de uma lista de tuplas. Porém, de modo a manter o formato COO, precisamos realizar a transposição do tensor, por meio do método <code>t</code>, além de aplicar o método <code>contiguous</code> em seguida."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8e7ca8c1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0, 1, 1, 2],\n",
       "        [1, 0, 2, 1]])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "edge_index = torch.tensor([[0,1],\n",
    "                           [1,0],\n",
    "                           [1,2],\n",
    "                           [2,1]], dtype=torch.long)\n",
    "\n",
    "edge_index = edge_index.t().contiguous()\n",
    "edge_index"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6260e180",
   "metadata": {},
   "source": [
    "## 1.2 - Representando as _features_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "767323a1",
   "metadata": {},
   "source": [
    "Para esse exemplo, cada nó terá apenas uma _feature_. Dessa forma, podemos definir o tensor como uma matriz coluna, em que cada linha representa as _features_ dos nós 0, 1 e 2 respectivamente. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ed4710e",
   "metadata": {},
   "source": [
    "Como as _features_ são as variáveis independentes do modelo, iremos referenciar tal tensor como <code>x</code>, além de atribuir o tipo de dado <code>torch.float</code>."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ada8cf0e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-1.],\n",
       "        [ 0.],\n",
       "        [ 1.]])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.tensor([[-1], [0], [1]], dtype=torch.float)\n",
    "x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9dcbbf65",
   "metadata": {},
   "source": [
    "## 1.3 - Criando a representação do grafo"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0585938",
   "metadata": {},
   "source": [
    "Por fim, de modo a representar o grafo G, precisamos apenas criar uma instância da classe <code>Data</code>, passando os tensores como argumentos do construtor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "73bfd5e6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Data(x=[3, 1], edge_index=[2, 4])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = Data(x=x, edge_index=edge_index)\n",
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfa8d6fd",
   "metadata": {},
   "source": [
    "Dessa forma, criamos a representação do grafo G, indicado pela imagem abaixo, no PyG. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8be9fd15",
   "metadata": {},
   "source": [
    "<figure>\n",
    "<img src=\"img/graph.svg\" alt=\"Grafo\" width='400'>\n",
    "    <figcaption>\n",
    "        <em>Fonte: \n",
    "            <a href='https://pytorch-geometric.readthedocs.io/en/latest/'>Documentação do Pytorch Geometric</a>\n",
    "        </em>\n",
    "    </figcaption>\n",
    "</figure>\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "754c4337",
   "metadata": {},
   "source": [
    "## 1.4 - Atributos e métodos"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bdacebe",
   "metadata": {},
   "source": [
    "A classe <code>Data</code> contem diversos parâmetros que retornam informações importantes da representação do grafo. Por exemplo, podemos visualizar a matriz que representa as arestas no formato COO:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c379e11d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0, 1, 1, 2],\n",
       "        [1, 0, 2, 1]])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.edge_index"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a140bf13",
   "metadata": {},
   "source": [
    "A fim da melhor visualização, podemos transpor essa matriz:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a1c4ae7d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0, 1],\n",
       "        [1, 0],\n",
       "        [1, 2],\n",
       "        [2, 1]])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.edge_index.t()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08c18253",
   "metadata": {},
   "source": [
    "Podemos visualizar também a matriz de _features_ que guarda as variáveis independentes do modelo:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ce0191b8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-1.],\n",
       "        [ 0.],\n",
       "        [ 1.]])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8734973e",
   "metadata": {},
   "source": [
    "Podemos saber a quantidade de nós do grafo:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1d9bafa5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.num_nodes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8abd45ae",
   "metadata": {},
   "source": [
    "Bem como o número de arestas:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9dd743fb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.num_edges"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60662906",
   "metadata": {},
   "source": [
    "Além da quantidade de _features_ por nó:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "580fdb00",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.num_features"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90c27852",
   "metadata": {},
   "source": [
    "Além disso, há métodos que retornnam também outras informações gerais acerca do grafo, como se ele possui nós isolados:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c7d9272c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.has_isolated_nodes()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26769147",
   "metadata": {},
   "source": [
    "Se possui grafos conectados a si (_self loops_):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "305ee392",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.has_self_loops()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6997ba8a",
   "metadata": {},
   "source": [
    "Por fim, se o grafo é dirigido:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d9458f71",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.is_directed()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60b61499",
   "metadata": {},
   "source": [
    "# 2- Dataset Cora"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5a4c3af",
   "metadata": {},
   "source": [
    "Até o presente momento, apenas verificamos como o PyG representa um grafo, bem como as informações que podemos extrair dele. A partir disso, já podemos trabalhar com um exemplo real."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c59654e",
   "metadata": {},
   "source": [
    "Para tanto, o PyG disponibiliza diversos datasets, dentre eles, o <code>Cora</code>, presente na coleção <code>Planetoid</code>, um dos mais empregados para benchmark. Abaixo, há uma breve descrição do dataset:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0018cc9f",
   "metadata": {},
   "source": [
    ">\n",
    ">O dataset Cora é constituído por 2708 publicações de Machine Learning classificadas entre 7 categorias:\n",
    "> - Baseado em Caso\n",
    "> - Algortimos Genéticos\n",
    "> - Redes Neurais\n",
    "> - Métodos Probabilísticos\n",
    "> - Aprendizagem por Reforço\n",
    "> - Regra de Aprendizagem\n",
    "> - Teoria\n",
    ">\n",
    ">Os artigos foram selecionados de sorte que todos citam ou são citados por ao menos outro artigo. No total, há 5429 links de citação.\n",
    ">\n",
    ">Com base na frequência de palavras relevantes dos documentos, foi criado um vocabulário com 1433 palavras únicas. Cada publicação é descrito por um vetor binário que corresponde a presença ou ausência de determinada palavra do vocabulário.\n",
    ">\n",
    ">_Fonte: https://linqs.soe.ucsc.edu/data_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "539f816d",
   "metadata": {},
   "source": [
    "A partir da descrição acima, podemos inferir algumas características do grafo que representa o dataset <code>Cora</code>. Nesse contexto, as publicações são referentes aos nós; as citações, às arestas. Além disso, o vetor binário indicando a presença ou ausência de palavras do vocabulário na publicação representa o vetor de _features_ de cada nó. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d80939a",
   "metadata": {},
   "source": [
    "Dessa forma, teríamos um grafo com 2708 nós (publicações), 5429 arestas (links de citação) e 1433 _features_ para cada nó. Podemos ter uma breve ideia da forma desse grafo com base na imagem abaixo. Cada cor represente uma dentre as 7 classes (_labels_) possíveis para os nós:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48a7e72d",
   "metadata": {},
   "source": [
    "<figure>\n",
    "<img src=\"img/cora.jpg\" alt=\"Cora\" width='450'>\n",
    "    <figcaption>\n",
    "        <em>Fonte: \n",
    "            <a href='https://paperswithcode.com/dataset/cora'>PapersWithCode</a>\n",
    "        </em>\n",
    "    </figcaption>\n",
    "</figure>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25c63ecc",
   "metadata": {},
   "source": [
    "## 2.1- Importando o dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc507777",
   "metadata": {},
   "source": [
    "Para ter acesso a qualquer dataset disponibilizado pelo PyG, deve-se importar a classe referente à coleção do dataset a partir de <code>torch_geometric.datasets</code>. Nesse caso, o Cora está presente na coleção <code>Planetoid</code>. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "461b5ff2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch_geometric.datasets import Planetoid"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "266f283b",
   "metadata": {},
   "source": [
    "Agora, devemos especificar o diretório de destino (<code>root</code>), bem como o nome (<code>name</code>) do dataset. Caso não se encontre no local, então o PyG irá realizar o download dos arquivos brutos (_raw_) do dataset, convertendo posteriormente para o formato <code>Data</code> já discutido. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "169c5c30",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = Planetoid(root='.', name='Cora')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c0341e0",
   "metadata": {},
   "source": [
    "No exemplo acima, o destino final do dataset é o mesmo diretório deste notebook <code>'.'</code>. Então, é possível visualizar a criação da pasta Cora. Dentro dela, há duas pastas: _raw_ e _processed_. Na primeira, constam os arquivos originais do dataset; na segundo, os empregados pelo PyG para representar o dataset como um grafo no formato <code>Data</code> originados a partir do processamentos dos primeiros."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c7e8704",
   "metadata": {},
   "source": [
    "## 2.2- Visualizando o dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9a6b9e0",
   "metadata": {},
   "source": [
    "Uma vez inicializado, podemos visualizar algumas informações do dataset. Por exemplo, seu tamanho, isto é, a quantidade de grafos que possui:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "f04b5e89",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f062d24a",
   "metadata": {},
   "source": [
    "No total, há apenas um grande grafo que representa todo o dataset. Além disso, podemos verificar a quantidade de classes (_labels_) dos nós:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "524c9f42",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.num_classes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0612f80",
   "metadata": {},
   "source": [
    "Conforme exposto pela descrição, há de fato 7 classes. Podemos também verificar o número de _features_ dos nós:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "47b6d445",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1433"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.num_node_features"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a515ff43",
   "metadata": {},
   "source": [
    "Dessa forma, é possível constatar que há 1433 _features_ por nó de fato."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bc9a2c4",
   "metadata": {},
   "source": [
    "Agora, vamos referenciar o grafo do dataset. Nesse caso, como mencionado, há apenas um grande grafo, porém há datasets que contêm diversos grafos, especialmente para problemas de classificação em nível de nó, cada um acessado por meio de um index posicional."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "9e41e704",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = dataset[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "829d0188",
   "metadata": {},
   "source": [
    "A partir disso, podemos verificar se o grafo retornado realmente é uma instância da classe <code>Data</code> conforme mencionado."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "a54cd5a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">> O grafo é instâncida de Data\n"
     ]
    }
   ],
   "source": [
    "text = 'O grafo é instâncida de Data' if isinstance(data, Data) else 'O grafo não é instância de Data'\n",
    "print(f'>> {text}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81b9cbf4",
   "metadata": {},
   "source": [
    "Além disso, podemos verificar também se é um grafo dirigido ou não:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "89cb3460",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">> O grafo não é dirigido\n"
     ]
    }
   ],
   "source": [
    "text = 'O grafo não é dirigido' if data.is_undirected() else 'O grafo é dirigido'\n",
    "print(f'>> {text}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e9781e1",
   "metadata": {},
   "source": [
    "Bem como a quantidade de nós e de arestas. Lembre que as arestas são computadas duas vezes na representação de um grafo não dirigido. Portando, devemos dividir o resultado pela metade."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "17c0c0f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">> # de nós: 2708\n",
      ">> # de arestas: 5278\n"
     ]
    }
   ],
   "source": [
    "num_nodes = data.num_nodes\n",
    "num_edges = data.num_edges\n",
    "print(f'>> # de nós: {num_nodes}')\n",
    "print(f'>> # de arestas: {num_edges//2}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32d33981",
   "metadata": {},
   "source": [
    "Dessa forma, constatamos haverm realmente 2708 nós (_publicações_), porém um pouco menos de arestas (_links de citações_) mencionadas na descrição. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fa668ef",
   "metadata": {},
   "source": [
    "Podemos utilizar uma forma mais compacta para verificar informações de cardinalidade do grafo ao simplesmente imprimir o objeto."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "e2001cb9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Data(x=[2708, 1433], edge_index=[2, 10556], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e8d692c",
   "metadata": {},
   "source": [
    "Aqui, podemos visualizar alguns parâmetros que nos informam sobre a quantidade de nós, arestas e _features_:\n",
    "\n",
    "><b>x</b>: informa as dimensões da matriz de _features_ [2708 linhas (nós), 1433 colunas (_features_)].\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "733fbe42",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2708, 1433])"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.x.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8f0bae3",
   "metadata": {},
   "source": [
    "><b>edge_index</b>: informa as dimensões da matriz de representação das arestas no formato COO [2 linhas (partida/destino), 10556 colunas (arestas para ambas direções)]."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "3d8eaa34",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 10556])"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.edge_index.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2223b1bf",
   "metadata": {},
   "source": [
    "Além disso, novos parâmetros surgiram, trazendo novas informações:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0ab865d",
   "metadata": {},
   "source": [
    "><b>y</b>: vetor que representa as _labels_, isto é, a variável que desejamos predizer do dataset. Pode ter dimensões variadas. Para predições em nível de grafo, possui apenas uma linha. Já para predições em nível de nó, possui uma linha para cada nó no grafo. O grafo atual se encaixa nesta categoria [2780 nós]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "497123b9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([3, 4, 4,  ..., 3, 3, 3])"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.y"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f85155bf",
   "metadata": {},
   "source": [
    "><b>train_mask</b>: vetor booleano que especifica quais nós são reservados para o treinamento [2780 nós]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "4a8b9984",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ True,  True,  True,  ..., False, False, False])"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.train_mask"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a4961fa",
   "metadata": {},
   "source": [
    "><b>val_mask</b>: vetor booleano que especifica quais nós são reservados para a validação [2780 nós]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "61dbe774",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([False, False, False,  ..., False, False, False])"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.val_mask"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79b8ec6f",
   "metadata": {},
   "source": [
    "><b>test_mask</b>: vetor booleano que especifica quais nós são reservados para o teste [2780 nós]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "2f3edf27",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([False, False, False,  ...,  True,  True,  True])"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.test_mask"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5263c3b",
   "metadata": {},
   "source": [
    "Dessa forma, para o dataset em questão, não precisamos nos preocupar na divisão em conjunto de treinamento, validação e teste. Isso já está estabelecido de acordo com as máscaras."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "182dc025",
   "metadata": {},
   "source": [
    "# 3- Modelo"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df59b481",
   "metadata": {},
   "source": [
    "Então, finalmente chegou o momento de criarmos nosso modelo utilizando GNNs (_Graph Neural Networks_). Porém, primeiro vamos pensar que tarefa desejamos realizar com esse modelo, isto é, qual tipo de predição desejamos fazer?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b7edfb7",
   "metadata": {},
   "source": [
    "Bem, temos um dataset representado por um grafo, cujas _labels_, isto é, aquilo que desejamos predizer, se referem aos nós do grafo. Nesse caso, elas representam a categoria (dentre 7) do artigo em questão. Dessa forma, desejamos fazer predições em nível de nó, ou seja, predizer a categoria de artigos que não foram apresentados ao modelo durante o treinamento."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e866cd4",
   "metadata": {},
   "source": [
    "## 3.1- Imports e considerações necessárias"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "437cb911",
   "metadata": {},
   "source": [
    "Para iniciar o implementação do nosso modelo, precisamos importar a classe base para qualquer modelo de rede neural do Pytorch:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "5ed45859",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.nn import Module"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91c0cacd",
   "metadata": {},
   "source": [
    "Além disso, iremos importar o módulo do Pytroch com diversas funcionalidade que podem ser usadas durante a implementação do modelo como, por exemplo, as funções de ativação."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "70bdd279",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0e0e0f5",
   "metadata": {},
   "source": [
    "Precisamos definir também a arqutetura empregada no modelo. Como exposto na <a href='https://docs.google.com/presentation/d/10DHKI-UI_10aSF2zTca5n06xkZS900iCdYVD2HyMFrc/edit?usp=sharing'> apresentação</a>, entre as arquiteturas disponíveis para grafos, encontra-se a GCN (_Graph Convolutional Networks_). Nesse contexto, para tal arquitetura, ainda podemos escolher entre diversas formas de implementar as camadas de convolução. No entanto, para este exemplo, empregaremos o operador de convolução <code>GCNConv</code> descrita por <a href='https://arxiv.org/abs/1609.02907'>Kipf e Welling (2017)</a>. \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "ae0810fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch_geometric.nn import GCNConv"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "347d46f0",
   "metadata": {},
   "source": [
    "Outro aspecto também discutido na <a href='https://docs.google.com/presentation/d/10DHKI-UI_10aSF2zTca5n06xkZS900iCdYVD2HyMFrc/edit?usp=sharing'> apresentação</a> são os vetores de _embeddings_, que representam a agragação de informações dos nós vizinhos. O tamanho de tal vetor geralmente difere da quantidade de _features_ dos nós, sendo uma decisão de hiperparâmetro. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "167d88b7",
   "metadata": {},
   "source": [
    "EMBEDDING_SIZE = 16"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a33cafc6",
   "metadata": {},
   "source": [
    "## 3.2- Implementação"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f456eb3",
   "metadata": {},
   "source": [
    "Pronto, a partir disso, já é possível implementar o modelo:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "60e202af",
   "metadata": {},
   "outputs": [],
   "source": [
    "#O modelo herda a classe Module (base para qualquer modelo de nn)\n",
    "class GCN(Module):\n",
    "    def __init__(self):\n",
    "        #A classe herdada é inicializada\n",
    "        super().__init__()\n",
    "        \n",
    "        #São definidas duas camadas de convolução\n",
    "        \n",
    "        #A primeira camada recebe os vetores de features dos nós, construindo o embedding\n",
    "        self.conv1 = GCNConv(dataset.num_node_features, EMBEDDING_SIZE)\n",
    "        #A segunda camada recebe o embedding, predizendo a classe como saída\n",
    "        self.conv2 = GCNConv(EMBEDDING_SIZE, dataset.num_classes)\n",
    "\n",
    "    def forward(self, data):\n",
    "        #Referenciamos a matriz de features e a conectividade do grafo para os nós repassados em data\n",
    "        x, edge_index = data.x, data.edge_index\n",
    "        \n",
    "        x = self.conv1(x, edge_index) #Repassamos esses dados para a primeira camada\n",
    "        x = F.relu(x) #Não linearidade é adicionada\n",
    "        x = F.dropout(x, training=self.training) #Realiza-se o processo de dropout\n",
    "        x = self.conv2(x, edge_index) #Embedding é repassado para a segunda camada\n",
    "\n",
    "        return F.log_softmax(x, dim=1)#Não lineariedade é aplicada"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ae7ffe7",
   "metadata": {},
   "source": [
    "Vamos analisar a implementação linha a linha para entender o que está sendo feito."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ad43fa3",
   "metadata": {},
   "source": [
    "Na primeira linha, definimo a classe GCN que representará nosso modelo, o qual deve herdar a classe <code>torch.nn.Module</code>, a classe base para qualquer modelo de rede neural."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bc30660",
   "metadata": {},
   "source": [
    "Na classe GCN, iremos definir dois métodos: <code>\\_\\_init__</code> e <code>forward</code>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1a04173",
   "metadata": {},
   "source": [
    "### 3.4- Método \\_\\_init__( )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2283cc94",
   "metadata": {},
   "source": [
    "No método <code>\\_\\_init__</code>, iremos inicializar a classe, bem como definir a topologia da rede neural. Dessa forma: "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87ac2975",
   "metadata": {},
   "source": [
    "1. Na primeira linha do método, inicializamos a classe herdada. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c77722c5",
   "metadata": {},
   "source": [
    "2. Na segunda linha, definimos nossa primeira camada de convolução <code>self.conv1</code>, a qual aplica o operador convolucional <code>GCNConv</code>. Nesse caso, precisamos especificar para o operador o tamanho de entrada e de saída dos dados. No primeiro caso, como os dados de entrada são os vetores de _features_, o tamanho é de <code>data.num_node_features</code>. Já no segudno, como os dados de saída são os _embeddings_, o tamanho é de <code>EMBEDDING_SIZE</code>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4302bba2",
   "metadata": {},
   "source": [
    "3. Na terceira linha, definimos nossa segunda camada de convolução <code>self.conv2</code>, a qual aplica o operador convolucional <code>GCNConv</code>. Nesse caso, precisamos especificar novamente o tamanho de entrada e de saída dos dados para o operador. No primeiro caso, como os dados de entrada são os vetores de _embedding_, o tamanho é de <code>EMBEDDING_SIZE</code>. Já no segudno, como os dados de saída são as classes dos artigos, o tamanho é de <code>data.num_classes</code>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52d64f78",
   "metadata": {},
   "source": [
    "A fim de melhor visualizar o procedimento adotado, imagine que parte do grafo é representado pela imagem abaixo, destacando o vetor de _featares_ do nó A."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab9b761f",
   "metadata": {},
   "source": [
    "<figure>\n",
    "    <img src='img/imp1.png' alt='Grafo genérico'>\n",
    "    <figcaption><em>Fonte: própria </em></figcaption>\n",
    "</figure>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0a5bbee",
   "metadata": {},
   "source": [
    "A primeira camada será responsável por receber o vetor de _features_ do nó A. Por isso, especificamos a quantidade de _features_ no canal de entrada. Além disso, ela executará o primeiro nível de agregação, resultando no primeiro vetor de _embeddings_ para o nó A."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "924fd40e",
   "metadata": {},
   "source": [
    "Em seguida, a segunda camada irá receber o vetor de _embeddings_ do nó A. Por isso, especificamos o tamanho dele para o canal de entrada. Por fim, ela irá realizar a classificação do nó entre as 7 possíveis classes definidas."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "916ee55d",
   "metadata": {},
   "source": [
    "Então, a topoplogia da rede pode ser visualizada da seguinte forma:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ae73379",
   "metadata": {},
   "source": [
    "<figure>\n",
    "    <img src='img/imp2.png' alt='Topologia'>\n",
    "    <figcaption><em>Fonte: própria </em></figcaption>\n",
    "</figure>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "755d81a3",
   "metadata": {},
   "source": [
    "### 3.5- Método forward( )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67af0074",
   "metadata": {},
   "source": [
    "No método <code>forward</code>, definimos a regra de propagação da rede neural, ou seja, a computação realizada pelo modelo para realizar uma predição. Perceba que até o momendo só falamos na estrutura da rede. Dessa forma:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebfff238",
   "metadata": {},
   "source": [
    "1. Na primeira linha, referenciamos a matriz de _features_ <code>x</code>, bem como a conectividade do grafo <code>edge_index</code>, repassado do modelo por meio do atributo data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf2e7b7b",
   "metadata": {},
   "source": [
    "2. Na segunda linha, repassamos esses dados para a primeira camada."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bad90b0",
   "metadata": {},
   "source": [
    "3. Na terceira linha, adicionamos uma função de ativação na saída da primeira camada. As funções de ativação são muito imporantes para um modelo, pois elas adicionam não-linearidade, dessa forma expandindo a capacidade de classificação. Além disso, elas definem quais valores são repassados para as próximas camadas. Nesse caso, empregamos a unidade linear refificada (ReLu). Ela simplesmente retorna o valor do neurônio, se for positivo; 0, se for negativo. O comportamento da função pode ser visto pelo gráfico abaixo:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "e24c59d1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7ff616cc3610>]"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "relu = lambda x: 0 if x <=0 else x \n",
    "\n",
    "x = np.linspace(-2.0, 2.0, 1000)\n",
    "y = np.array([relu(_) for _ in x])\n",
    "plt.plot(x,y)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5017b71e",
   "metadata": {},
   "source": [
    "4. Na quarta linha, aplicamos a técninca de dropout, um algoritmo recentemente introduzido no treinamento de redes neurais que tem demonstrado excelentes resultados. Nele, neurônios são temporariamente retirados do modelo de forma aleatória em cada época. Assim, pode-se pensar que diversos modelos diferentes são treinados, já que a topologia da rede muda, tendo como resultado o efeito médio de todas essas redes diferentes. Uma das vantagens da técninca é, por exemplo, evitar o problema de superadaptação dos dados (_overfitting_) ao generalizar o poder de inferência do modelo. O efeito do dropout é ilustrado abaixo:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bf9d11d",
   "metadata": {},
   "source": [
    "<figure>\n",
    "    <img src='img/dropout.png' height='100'>\n",
    "    <figcaption><em>Fonte: <a href='https://www.deeplearningbook.com.br/capitulo-23-como-funciona-o-dropout/'>DeepLearningBook</a> </em></figcaption>\n",
    "</figure>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2ab7e89",
   "metadata": {},
   "source": [
    "5. Na quinta linha, repassamos os resultados para a segunda camada."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "682259d2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
